Captain! Graph the data flow through gitr.cpp. I think that is going to be the best way to
figure out what is going on in there.

Captain! Workflow after the examples are tested and verified: you need to have 2 windows,
of 2 panels each. One needs to be jerome's gitr and jerome.cpp
the other needs to be gitr.cpp and the other relevant files.
Copy it all over, then compile and test. If it passes, you're golden. Merge it in. By then,
hopefully you will have had a change to meet with Tim and ask

1. What is the deal with the input distribution grids for the surface models? According to
   what rules are they regridded and made into cdfs?

2. What is the meaning of the options and their values? Which ones are deprecated and can be
   removed?

3. Get some more examples that test all the options Tim tells you matter. Get these as PyGITR
   examples from Alyssa

4. Verify changes to the build options and the file interface. Switch to hdf5 file interface.
   Make netcdf optional and NOT enabled by default.

5. Merge all outstanding branches, tag a release.

6. Start the multi-species unit test.

7. Heavy refactor of source code.

8. Time dependence.

9. Geometry hashing stuff.

10. Automatic domain balancing

11. Interfacing with NDIP


What about integrating GITR stuff and runs into the data analysis? What if you used your
machines at home to set up a server and token issuer to do an ssh connection? Can you replicate
what they have on the site? Replicate their tech stack - you know it's there!

Also write detailed comments in user_options.cmake explaining what the options are and what the
different values for the options mean.

kubernetes

get aaron involved in the vis



Goals by tomorrow:

1. Get everything installed and building and running on fusiont6 for Atul tomorrow

2. Figure out how to make GITR generate the hashes.

3. Get the simple CPC example working. Use the hashes for that. Run it and get output. Run it
   3x: once on dev, once on your branch of netcdf. If they don't match, start running on
   intermediate commits.

4. Remove netcdf completely from GITR.

5. Integrate with the new build system. Compare outputs. Merge. Do runtime config.

Action plan:

1. Compile GITR on fusiont6
2. Finish the netcdf changes
3. Run the CPC example on fusiont5 while this is happening



This file will collect and explain all the steps

0. Important files:

   examples/cmod_meshing_gitr_erosion.m

     - this file creates a geometryPointPlane3D.cfg from an input stl file

     - also creates particle_source_cmod.nc

   examples/meshing/gitr_meshing_example.m

     - this file creates a geometryPointPlane3D.cfg from an input stl file


1. ADAS_Rates_Al.nc ---> material constants. Comes from known online data.

2. ftryDynSelf.nc ---> self-sputtering and redeposition coefficients/yields? Comes from ftrydyn

3. hashing file for geometry

4. hashing file for sheath

5. geometryPointPlane3D.cfg ---> generated from STL file by a matlab script
   Captain! This is in examples/meshing

6. gitrInput.cfg ---> this is the flags and options. Main config file.

7. helicon_processing.m ---> graphing script, not important

8.  particle_source_helicon.nc ---> particle sources.
    what is a particle source? Where they will be created. Initially? Location of eroded
    particles.

    How can you specify the location of eroded particles before the erosion occurs?

    simple assumption is that particle source covers the whole surface. Is it a 3d geometry
    laying on top of the surface?

    Particle source is a list of triangles that can produce impurity particles?

    In the largest case, it is all the triangles?

    In the efficient case, it is only some of the triangles that are significant?

    The red surface was every triangle.

    Each triangles has a surface normal?

    Question: why does geometryPointPlane3D not include the surface normals?

    Answer: because not all surface normals need to be calculated, only the ones that can
            potentially generate eroded impurity particles

    Which script produces particle_source_helicon.nc? Example script for the cmod case

    Captain! this is in examples/meshing/cmod_meshing_gitr_erosion.m


    Is it something like this:

    geometryPointPlane3D.cfg: triangle_0 ... triangle_1 ... triangle_2 ...

    particle_source_helicon:  [ 0, 2 ] (but not 1)

    figure out the other stuff from reading the scripts


9. profilesProtoMPEx.nc - what is this one? Magnetic fields, temp, density of the background
   plasma? Background plasma profiles. Stuff that isn't an impurity.

   2D profiles? Ah, they are extrapolated to 3D I think. 

   Is this information superimposed on top of geometryPointPlane3D.cfg?

   All data is on the geometry. So this is where BFIELD_INTERP reads from etc?

   where does this file come from? This comes from an external code like SOLPS.

   SOLPS outputs file_0, script_0 consumes file_0 and outputs profilesProtoMPEx.nc?

   next piece is find examples of file_0 and script_0. Not a single dedicated script but there
   probably could be

   currently, Atul has fake versions of file_0. What script_0 are you using?

   there is a github repo containing script_0, it is complicated.

   background plasma, temp, and density profiles can come from many different sources.

   just rely on an existing file

Questions we still have:

How exactly is hashing activated? One value for hashing causes it to be created as an output,
another causes it to be consumed as input. Which is which?


hashing files generated by a matlab script:




























